{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Importing required libraries"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"!pip install 'tensorflow==1.15.3'","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt # plotting\nfrom PIL import Image\nimport matplotlib.patches as patches\nimport matplotlib.image as IMG\nimport numpy as np # linear algebra\nimport os # accessing directory structure\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport scipy.io\nimport tensorflow as tf\nimport tensorflow_addons as tfa\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **How to read mat files?**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def mat_to_boundbox(filename):\n    input = scipy.io.loadmat(filename)['boxes']\n    box_numbers = input.shape[-1]\n    bx1_e1 = input[0][0][0][0][0][0]\n    bx1_e2 = input[0][0][0][0][1][0]\n    bx1_e3 = input[0][0][0][0][2][0]\n    bx1_e4 = input[0][0][0][0][3][0]\n    bx1 = np.array([bx1_e1,bx1_e2,bx1_e3,bx1_e4])\n    output = np.array(bx1)\n    output = np.flip(output,1)\n    output = np.reshape(output,(1,4,2))\n    if box_numbers == 2:\n        bx2_e1 = input[0][1][0][0][0][0]\n        bx2_e2 = input[0][1][0][0][1][0]\n        bx2_e3 = input[0][1][0][0][2][0]\n        bx2_e4 = input[0][1][0][0][3][0]\n        bx2 = [bx2_e1,bx2_e2,bx2_e3,bx2_e4]\n        output = np.array([bx1,bx2])\n        output = np.flip(output,2)\n   \n    return output\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Draw bounding box"},{"metadata":{"trusted":true},"cell_type":"code","source":"def drawBoundbox(image,coordinate):\n    plt.figure()\n    plt.imshow(img)\n    if coordinate.shape[0] >= 1:\n        plt.scatter(x=[coordinate[0][0][0],coordinate[0][1][0],coordinate[0][2][0],coordinate[0][3][0]], y=[coordinate[0][0][1],coordinate[0][1][1],coordinate[0][2][1],coordinate[0][3][1]], c='r', s=20)\n    if coordinate.shape[0] == 2:\n        plt.scatter(x=[coordinate[1][0][0],coordinate[1][1][0],coordinate[1][2][0],coordinate[1][3][0]], y=[coordinate[1][0][1],coordinate[1][1][1],coordinate[1][2][1],coordinate[1][3][1]], c='g', s=20)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Resize and edit bounding boxs coordinates"},{"metadata":{"trusted":true},"cell_type":"code","source":"def resize_edit_box(imagefile,coordinatefile):\n    img = Image.open(imagefile)\n    img1 = img.resize((512,512),0)\n    img_shape = np.array(img).shape\n    img = np.array(img1)\n    \n    x_scale = 512 / img_shape[1]\n    y_scale = 512/ img_shape[0]\n    \n    coordinate = mat_to_boundbox(coordinatefile)\n    \n    if coordinate.shape[0] == 1:\n        changed_x_coordinate = np.reshape(coordinate[:,:,0]*x_scale,(1,4,1))\n        changed_y_coordinate = np.reshape(coordinate[:,:,1]*y_scale,(1,4,1))\n    if coordinate.shape[0] == 2:\n        changed_x_coordinate = np.reshape(coordinate[:,:,0]*x_scale,(2,4,1))\n        changed_y_coordinate = np.reshape(coordinate[:,:,1]*y_scale,(2,4,1))\n        \n    coordinate = np.concatenate((changed_x_coordinate, changed_y_coordinate), axis=2)\n    \n    return img , coordinate\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testImage_path = '/kaggle/input/hand_dataset/training_dataset/training_data/images/Buffy_110.jpg'\ntestAnnotation_path = '/kaggle/input/hand_dataset/training_dataset/training_data/annotations/Buffy_110.mat'\n\nimg, coordinate = resize_edit_box(testImage_path,testAnnotation_path)\ndrawBoundbox(img, coordinate)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Chenging Coordinate format to Center(X),Center(Y),Height , Weight"},{"metadata":{"trusted":true},"cell_type":"code","source":"def distance(point1,point2):\n    distance = ((point2[0] - point1[0])**2 + (point2[1] - point1[1])**2)**0.5\n    return distance\n\n\n\ndef coordinate_reformat(coordinate):\n    if coordinate.shape[0] >= 1:\n        x_center = (coordinate[0,0,0] + coordinate[0,2,0])/2\n        y_center = (coordinate[0,0,1] + coordinate[0,2,1])/2\n        height = np.amax(coordinate[0,:,1]) - np.amin(coordinate[0,:,1])\n        weight = np.amax(coordinate[0,:,0]) - np.amin(coordinate[0,:,0])\n        output = np.array([x_center,y_center,height,weight]).reshape(1,4,1)\n        \n        \n    if coordinate.shape[0] == 2:\n        x_center_2 = (coordinate[1,0,0] + coordinate[1,2,0])/2\n        y_center_2 = (coordinate[1,0,1] + coordinate[1,2,1])/2\n        height_2 = np.amax(coordinate[1,:,1]) - np.amin(coordinate[1,:,1])\n        weight_2 = np.amax(coordinate[1,:,0]) - np.amin(coordinate[1,:,0])\n        temp = np.array([x_center_2,y_center_2,height_2,weight_2]).reshape(1,4,1)\n        output = np.concatenate((output, temp), axis=0).reshape(2,4,1)\n        \n    return output\n\n\ndef coordinate_main(Newcoordinate):\n    center_x = Newcoordinate[0,0,0]\n    center_y = Newcoordinate[0,1,0]\n    height = Newcoordinate[0,2,0]\n    weidth = Newcoordinate[0,3,0]\n    \n    if Newcoordinate.shape[0] >= 1:\n        a = np.array([center_x - (height/2 + weidth/2), center_y - (height/2 + weidth/2)])\n        b = np.array([center_x - (height/2 - weidth/2), center_y - (height/2 - weidth/2)])\n        c = np.array([center_x - (-height/2 - weidth/2), center_y - (-height/2 - weidth/2)])\n        d = np.array([center_x - (-height/2 + weidth/2), center_y - (-height/2 + weidth/2)])\n        temp1 = np.concatenate((a,b,c,d),axis = 0).reshape(1,4,2)\n        \n    \n    if Newcoordinate.shape[0] == 2:\n        center_x = Newcoordinate[1,0,0]\n        center_y = Newcoordinate[1,1,0]\n        height = Newcoordinate[1,2,0]\n        weidth = Newcoordinate[1,3,0]\n        a = np.array([center_x - (height/2 + weidth/2), center_y - (height/2 + weidth/2)])\n        b = np.array([center_x - (height/2 - weidth/2), center_y - (height/2 - weidth/2)])\n        c = np.array([center_x - (-height/2 - weidth/2), center_y - (-height/2 - weidth/2)])\n        d = np.array([center_x - (-height/2 + weidth/2), center_y - (-height/2 + weidth/2)])\n        temp2 = output = np.concatenate((a,b,c,d),axis = 0).reshape(1,4,2)\n        \n        output = np.concatenate((temp1, temp2), axis = 0)\n        \n    return output","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Find appropriate anchor boxes"},{"metadata":{"trusted":true},"cell_type":"code","source":"all_coordinate = np.empty([2])\nfor dirname, _, filenames in os.walk('../input/hand_dataset/training_dataset/training_data/annotations'):\n    for filename in filenames:\n        if 'Buffy' in filename: \n            temp = coordinate_reformat(mat_to_boundbox(os.path.join(dirname, filename))).reshape(1,-1,4)\n            if all_coordinate.shape[0] == 2:\n                all_coordinate = temp\n            else:\n                all_coordinate = np.concatenate((temp,all_coordinate),axis = 1)\n                \nprint(all_coordinate.shape)\nplt.plot(all_coordinate[0,:,2],all_coordinate[0,:,3],'ro') \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.cluster import KMeans\nall_coordinate = all_coordinate.reshape(-1,4)\nHW = all_coordinate[:,2:4]\nkmeans = KMeans(n_clusters=1, random_state=0).fit(HW)\nkmeans.cluster_centers_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**So appropriate anchor size is [51.49931633, 49.05936578]**"},{"metadata":{"trusted":true},"cell_type":"code","source":"anchor_DEFUALT = np.array([51.49931633, 49.05936578])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Creating CSV dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_output(imgFile, annoFile, grid = 16):\n    img, coordinate = resize_edit_box(imgFile, annoFile)\n    coordinate = coordinate_reformat(coordinate)\n    step = img.shape[1]/grid\n    output = np.zeros((5,grid,grid))\n    boundBox_grid_x = int(coordinate[0,0,0]/step)\n    if boundBox_grid_x == 16: boundBox_grid_x = 15\n    boundBox_grid_y = int(coordinate[0,1,0]/step)\n    if boundBox_grid_y == 16: boundBox_grid_y = 15\n    boundBox_x = (coordinate[0,0,0]% step)/step\n    boundBox_y = (coordinate[0,1,0]% step)/step\n    boundBox_height = coordinate[0,2,0]/(anchor_DEFUALT[0] * grid)\n    boundBox_weidth = coordinate[0,3,0]/(anchor_DEFUALT[1] * grid)\n    temp = np.array([1, boundBox_x, boundBox_y, boundBox_height, boundBox_weidth]).reshape(5)\n    output[:,boundBox_grid_x,boundBox_grid_y] = temp\n    \n    if coordinate.shape[0] == 2:\n        boundBox_grid_x = int(coordinate[1,0,0]/step)\n        if boundBox_grid_x == 16: boundBox_grid_x = 15\n        boundBox_grid_y = int(coordinate[1,1,0]/step)\n        if boundBox_grid_y == 16: boundBox_grid_y = 15\n        boundBox_x = (coordinate[1,0,0]% step)/step\n        boundBox_y = (coordinate[1,1,0]% step)/step\n        boundBox_height = coordinate[1,2,0]/(anchor_DEFUALT[0] * grid)\n        boundBox_weidth = coordinate[1,3,0]/(anchor_DEFUALT[1] * grid)\n        temp1 = np.array([1, boundBox_x, boundBox_y, boundBox_height, boundBox_weidth]).reshape(5)\n        output[:,boundBox_grid_x,boundBox_grid_y] = temp1\n        \n    return img, output\n    \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import csv\n\ncsv_head = [\"no.\"]\nfor i in range(0,262144):\n    csv_head.append(\"pixel \" + str(i))\nfor i in range(0,256):\n    csv_head.append(\"Objectness score(gride\"+str(i)+\")\"), csv_head.append(\"Center x(gride\"+str(i)+\")\"), csv_head.append(\"Center y(gride\"+str(i)+\")\"), csv_head.append(\"Height(gride\"+str(i)+\")\"), csv_head.append(\"Width(gride\"+str(i)+\")\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_dataset(images,annotations):\n    counter = 0\n    final_output = []\n    temp = []\n    for IMGdir, _, IMGfiles in os.walk(images):\n        for ANNOdir, _, ANNOfiles in os.walk(annotations):\n             for img_file in IMGfiles:\n                    for anno_file in ANNOfiles:\n                        if counter == 1:break\n                        idx = img_file.index('.jpg')\n                        if 'Buffy' in img_file and img_file[0:idx]+'.mat' == anno_file:\n                            img = os.path.join(IMGdir, img_file)\n                            ann = os.path.join(ANNOdir, anno_file)\n                            img, out = create_output(img,ann)\n                            img = np.reshape(img,(1,-1)).tolist()[0]\n                            out = np.reshape(out,(1,-1),order='F').tolist()[0]\n                            temp = [counter] + img + out\n                            final_output.append(temp)\n                            counter+=1\n    return final_output","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainimg_dir = '../input/hand_dataset/training_dataset/training_data/images'\ntrainanno_dir = '../input/hand_dataset/training_dataset/training_data/annotations'\n#train = create_dataset(trainimg_dir, trainanno_dir)\ntestimg_dir = '../input/hand_dataset/test_dataset/test_data/images'\ntestanno_dir = '../input/hand_dataset/test_dataset/test_data/annotations'\n#test = create_dataset(testimg_dir, testanno_dir)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"write = []\nwrite.append(csv_head),write.append(train[0])\nwith open('dataset.csv', 'w', newline='') as file:\n    writer = csv.writer(file)\n    writer.writerows(write)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\ndf = pd.read_csv(\"./dataset.csv\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Generator"},{"metadata":{"trusted":true},"cell_type":"code","source":"def generator(images, annotations , batch_size=32):\n    \"\"\"\n    Yields the next training batch.\n    \"\"\"\n    \n   \n    while True:\n        counter = 0\n        X_train = []\n        y_train = []\n        for IMGdir, _, IMGfiles in os.walk(images):\n            for ANNOdir, _, ANNOfiles in os.walk(annotations):\n                 for img_file in IMGfiles:\n                        for anno_file in ANNOfiles:\n                            if counter == batch_size: \n                                X_train = np.array(X_train)\n                                y_train = np.array(y_train)\n                                yield X_train, y_train\n                                X_train = []\n                                y_train = []\n                                counter = 0\n                            idx = img_file.index('.jpg')\n                            if 'Buffy' in img_file and img_file[0:idx]+'.mat' == anno_file:\n                                img = os.path.join(IMGdir, img_file)\n                                ann = os.path.join(ANNOdir, anno_file)\n                                img, out = create_output(img,ann)\n                                X_train.append(img)\n                                y_train.append(out)\n                                counter+=1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_generator = generator(trainimg_dir, trainanno_dir, batch_size=32)\ntest_generator =  generator(testimg_dir, testanno_dir, batch_size=32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x, y = next(train_generator)\nprint(x.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model architecture"},{"metadata":{},"cell_type":"markdown","source":"batch normalization and fixed padding"},{"metadata":{"trusted":true},"cell_type":"code","source":"_BATCH_NORM_DECAY = 0.9\n_BATCH_NORM_EPSILON = 1e-05\n_LEAKY_RELU = 0.1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def batch_norm(inputs, training, data_format):\n    \"\"\"Performs a batch normalization using a standard set of parameters.\"\"\"\n    return tf.layers.batch_normalization(\n        inputs=inputs, axis=1 if data_format == 'channels_first' else 3,\n        momentum=_BATCH_NORM_DECAY, epsilon=_BATCH_NORM_EPSILON,\n        scale=True, training=training)\n\n\ndef fixed_padding(inputs, kernel_size, data_format):\n    \"\"\"ResNet implementation of fixed padding.\n\n    Pads the input along the spatial dimensions independently of input size.\n\n    Args:\n        inputs: Tensor input to be padded.\n        kernel_size: The kernel to be used in the conv2d or max_pool2d.\n        data_format: The input format.\n    Returns:\n        A tensor with the same format as the input.\n    \"\"\"\n    pad_total = kernel_size - 1\n    pad_beg = pad_total // 2\n    pad_end = pad_total - pad_beg\n\n    if data_format == 'channels_first':\n        padded_inputs = tf.pad(inputs, [[0, 0], [0, 0],\n                                        [pad_beg, pad_end],\n                                        [pad_beg, pad_end]])\n    else:\n        padded_inputs = tf.pad(inputs, [[0, 0], [pad_beg, pad_end],\n                                        [pad_beg, pad_end], [0, 0]])\n    return padded_inputs\n\n\ndef conv2d_fixed_padding(inputs, filters, kernel_size, data_format, strides=1):\n    \"\"\"Strided 2-D convolution with explicit padding.\"\"\"\n    if strides > 1:\n        inputs = fixed_padding(inputs, kernel_size, data_format)\n\n    return tf.layers.conv2d(\n        inputs=inputs, filters=filters, kernel_size=kernel_size,\n        strides=strides, padding=('SAME' if strides == 1 else 'VALID'),\n        use_bias=False, data_format=data_format)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Darknet 53"},{"metadata":{"trusted":true},"cell_type":"code","source":"def darknet53_residual_block(inputs, filters, training, data_format, strides=1):\n    \"\"\"Creates a residual block for Darknet.\"\"\"\n    shortcut = inputs\n\n    inputs = conv2d_fixed_padding(\n        inputs, filters=filters, kernel_size=1, strides=strides,\n        data_format=data_format)\n    inputs = batch_norm(inputs, training=training, data_format=data_format)\n    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n\n    inputs = conv2d_fixed_padding(\n        inputs, filters=2 * filters, kernel_size=3, strides=strides,\n        data_format=data_format)\n    inputs = batch_norm(inputs, training=training, data_format=data_format)\n    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n\n    inputs += shortcut\n\n    return inputs\n\n\ndef darknet53(inputs, training, data_format):\n    \"\"\"Creates Darknet53 model for feature extraction.\"\"\"\n    inputs = conv2d_fixed_padding(inputs, filters=32, kernel_size=3,\n                                  data_format=data_format)\n    inputs = batch_norm(inputs, training=training, data_format=data_format)\n    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n    inputs = conv2d_fixed_padding(inputs, filters=64, kernel_size=3,\n                                  strides=2, data_format=data_format)\n    inputs = batch_norm(inputs, training=training, data_format=data_format)\n    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n\n    inputs = darknet53_residual_block(inputs, filters=32, training=training,\n                                      data_format=data_format)\n\n    inputs = conv2d_fixed_padding(inputs, filters=128, kernel_size=3,\n                                  strides=2, data_format=data_format)\n    inputs = batch_norm(inputs, training=training, data_format=data_format)\n    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n\n    for _ in range(2):\n        inputs = darknet53_residual_block(inputs, filters=64,\n                                          training=training,\n                                          data_format=data_format)\n\n    inputs = conv2d_fixed_padding(inputs, filters=256, kernel_size=3,\n                                  strides=2, data_format=data_format)\n    inputs = batch_norm(inputs, training=training, data_format=data_format)\n    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n\n    for _ in range(8):\n        inputs = darknet53_residual_block(inputs, filters=128,\n                                          training=training,\n                                          data_format=data_format)\n\n    route1 = inputs\n\n    inputs = conv2d_fixed_padding(inputs, filters=512, kernel_size=3,\n                                  strides=2, data_format=data_format)\n    inputs = batch_norm(inputs, training=training, data_format=data_format)\n    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n\n    for _ in range(8):\n        inputs = darknet53_residual_block(inputs, filters=256,\n                                          training=training,\n                                          data_format=data_format)\n\n    route2 = inputs\n\n    inputs = conv2d_fixed_padding(inputs, filters=1024, kernel_size=3,\n                                  strides=2, data_format=data_format)\n    inputs = batch_norm(inputs, training=training, data_format=data_format)\n    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n\n    for _ in range(4):\n        inputs = darknet53_residual_block(inputs, filters=512,\n                                          training=training,\n                                          data_format=data_format)\n\n    return route1, route2, inputs","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Yolo convolution"},{"metadata":{"trusted":true},"cell_type":"code","source":"def yolo_convolution_block(inputs, filters, training, data_format):\n    \"\"\"Creates convolution operations layer used after Darknet.\"\"\"\n    inputs = conv2d_fixed_padding(inputs, filters=filters, kernel_size=1,\n                                  data_format=data_format)\n    inputs = batch_norm(inputs, training=training, data_format=data_format)\n    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n\n    inputs = conv2d_fixed_padding(inputs, filters=2 * filters, kernel_size=3,\n                                  data_format=data_format)\n    inputs = batch_norm(inputs, training=training, data_format=data_format)\n    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n\n    inputs = conv2d_fixed_padding(inputs, filters=filters, kernel_size=1,\n                                  data_format=data_format)\n    inputs = batch_norm(inputs, training=training, data_format=data_format)\n    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n\n    inputs = conv2d_fixed_padding(inputs, filters=2 * filters, kernel_size=3,\n                                  data_format=data_format)\n    inputs = batch_norm(inputs, training=training, data_format=data_format)\n    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n\n    inputs = conv2d_fixed_padding(inputs, filters=filters, kernel_size=1,\n                                  data_format=data_format)\n    inputs = batch_norm(inputs, training=training, data_format=data_format)\n    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n\n    route = inputs\n\n    inputs = conv2d_fixed_padding(inputs, filters=2 * filters, kernel_size=3,\n                                  data_format=data_format)\n    inputs = batch_norm(inputs, training=training, data_format=data_format)\n    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n\n    return route, inputs","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Detection layer"},{"metadata":{"trusted":true},"cell_type":"code","source":"def yolo_layer(inputs,data_format):\n    \n    n_anchors = 1\n    n_classes = 0\n\n    inputs = tf.layers.conv2d(inputs, filters=n_anchors * (5 + n_classes),\n                              kernel_size=1, strides=1, use_bias=True,\n                              data_format=data_format)\n\n   \n    if data_format != 'channels_first':\n        inputs = tf.transpose(inputs, [0, 3,1,2])\n    \n    confidence, box_centers, box_shapes = \\\n                                        tf.split(inputs, [1, 2, 2], axis=1)\n\n    confidence = tf.nn.sigmoid(confidence)\n    box_centers = tf.nn.sigmoid(box_centers)\n    box_shapes = tf.nn.leaky_relu(box_shapes)\n    box_shape_height = box_shapes[:,0,:,:]\n    box_shape_height = tf.reshape(box_shape_height,[1,1,16,16])\n    box_shape_width = box_shapes[:,1,:,:]\n    box_shape_width = tf.reshape(box_shape_width,[1,1,16,16])\n    box_shape_height = box_shape_height * 512 * anchor_DEFUALT[0]\n    box_shape_width = box_shape_width * 512 * anchor_DEFUALT[1]\n    box_shapes = tf.concat([box_shape_height,box_shape_width], axis =1)\n    inputs = tf.concat([confidence, box_centers, box_shapes], axis=1)\n\n    return inputs","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"testing outut tensor shape"},{"metadata":{"trusted":true},"cell_type":"code","source":"inputs = tf.random.uniform(shape=[1,512,512,3])\nprint(inputs.get_shape(),\"\\n\")\nroute1,route2, inputs = darknet53(inputs, training=True,data_format='channels_last')\nprint(inputs.get_shape(),\"\\n\")\nroute, inputs = yolo_convolution_block(inputs, filters=512, training=True,data_format='channels_last')\nprint(inputs.get_shape(),\"\\n\")\ninputs = yolo_layer(inputs,data_format='channels_last')\nprint(inputs.get_shape(),\"\\n\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Final YOLO model"},{"metadata":{"trusted":true},"cell_type":"code","source":"def ME_yolo(input_shape = (512,512,3),training=False, data_format='channels_last'):\n    inputs = Input(shape=input_shape)\n    route1,route2, inputs = darknet53(inputs,train, data_format)\n    route, inputs = yolo_convolution_block(inputs,512,train,data_format)\n    out = yolo_layer(inputs,data_format)\n    model = Model(inputs=inputs,outputs=out)\n    return model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Customized Loss function"},{"metadata":{"trusted":true},"cell_type":"code","source":"def hw_to_minmax(tensor):\n    \n    batch_size = np.array(tensor.get_shape())[0]\n    output = tf.zeros([batch_size,4,16,16])\n    y_min = tensor[:,1,:,:] - (tensor[:,2,:,:]/2) - (tensor[:,3,:,:]/2)\n    x_min = tensor[:,0,:,:] - (tensor[:,2,:,:]/2) - (tensor[:,3,:,:]/2)\n    y_max = tensor[:,1,:,:] + (tensor[:,2,:,:]/2) + (tensor[:,3,:,:]/2)\n    x_max = tensor[:,0,:,:] + (tensor[:,2,:,:]/2) + (tensor[:,3,:,:]/2)\n    output = tf.concat([y_min, x_min, y_max, x_max],1)\n    output = tf.reshape(output,[-1,4])\n    return output","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp1 = tf.reshape(tf.constant([5.0, 2.0, 6.0, 3.0]),[1,4,1,1])\ntemp2 = tf.reshape(tf.constant([5.0, 2.0, 6.0, 3.0]),[1,4,1,1])\ntemp = tf.concat([temp1,temp],0)\n\nhw_to_minmax(temp).numpy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gl = tfa.losses.GIoULoss()\nboxes1 = tf.constant([5.0, 2.0, 6.0, 3.0])\nboxes2 = tf.constant([5.0, 2.0, 8.0, 3.0])\nloss = gl(boxes1, boxes2)\nprint('Loss: ', loss.numpy())  # Loss: [1.07500000298023224, 1.9333333373069763]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gl = tfa.losses.GIoULoss()\ndef loss(model, x, y, training):\n  # training=training is needed only if there are layers with different\n  # behavior during training versus inference (e.g. Dropout).\n    y_pred = model(x, training=training)\n    confidence_true = y[:,0,:,:]\n    confidence_pred = y_pred[:,0,:,:]\n    loss_confidence = tf.keras.losses.MSE(confidence_true, confidence_pred)\n    boundbox_true = hw_to_minmax(y[:,1:4,:,:])\n    boundbox_pred = hw_to_minmax(y_pred[:,1:4,:,:])\n    loss_boundbox = gl(boundbox_true, boundbox_pred)\n    total_loss = tf.reduce_sum(loss_confidence) + tf.reduce_sum(loss_boundbox)\n    \n    return total_loss","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}